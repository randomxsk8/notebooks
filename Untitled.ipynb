{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports.ipynb\n",
    "import csv\n",
    "import getpass\n",
    "import cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/distributed/dashboard/core.py:74: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4939e065a4421b898cf7b1ddb2e191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>KubeCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=30)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://10.32.1.188:43721\n",
       "  <li><b>Dashboard: </b><a href='/user/carlo%20mariade%20marco1/proxy/34093/status' target='_blank'>/user/carlo%20mariade%20marco1/proxy/34093/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://10.32.1.188:43721' processes=0 cores=0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "callset_pass = callset_biallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_counts= zarr.open('data/phase2_biallel_allele_count.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "outgroup_allele_counts= zarr.open('data/outgroup_alleles_phase2.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outgroup_ascertainment(chrom, start, stop, outgroups):\n",
    "    \n",
    "    # locate region\n",
    "    pos = allel.SortedIndex(callset_pass[chrom]['variants/POS'][:])\n",
    "    locr = pos.locate_range(start, stop)\n",
    "    \n",
    "    # ascertain SNPs\n",
    "    loca = np.zeros(pos.shape, dtype='b1')\n",
    "    loca[locr] = True\n",
    "    log('outgroup ascertainment, initial', nnz(loca))\n",
    "    for s in outgroups:\n",
    "        ac = allel.AlleleCountsArray(outgroup_allele_counts[chrom][s][:])\n",
    "        # biallelic and non-missing\n",
    "        locs = (ac.max_allele() <= 1) & (ac.sum(axis=1) > 0)\n",
    "        loca &= locs\n",
    "        log(s, nnz(loca))\n",
    "        \n",
    "    return loca\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingroup_ascertainment(chrom, start, stop, segpops):\n",
    "\n",
    "    # locate region\n",
    "    pos = allel.SortedIndex(callset_pass[chrom]['variants']['POS'][:])\n",
    "    locr = pos.locate_range(start, stop)\n",
    "\n",
    "    # ascertain SNPs\n",
    "    loca = np.zeros(pos.shape, dtype='b1')\n",
    "    loca[locr] = True\n",
    "    log('ingroup ascertainment, initial', nnz(loca))\n",
    "\n",
    "    \n",
    "    # require segregating\n",
    "    for pop in segpops:\n",
    "        ac = allel.AlleleCountsArray(allele_counts[chrom][pop][:, :2])\n",
    "        loc_seg = (ac.min(axis=1) > 0)\n",
    "        loca &= loc_seg\n",
    "        log('after require segregating in', pop, nnz(loca))\n",
    "        \n",
    "    return loca\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ld_prune(pos, gn, size, step, threshold=.1, n_iter=1):\n",
    "    for i in range(n_iter):\n",
    "        loc_unlinked = allel.locate_unlinked(gn, size=size, step=step, threshold=threshold)\n",
    "        n = np.count_nonzero(loc_unlinked)\n",
    "        n_remove = gn.shape[0] - n\n",
    "        log('iteration', i+1, 'retaining', n, 'removing', n_remove, 'variants')\n",
    "        gn = gn.compress(loc_unlinked, axis=0)\n",
    "        pos = pos.compress(loc_unlinked)\n",
    "    return pos, gn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_treemix(acs, fn):\n",
    "    pops = sorted(acs.keys())\n",
    "    n_variants = acs[pops[0]].shape[0]\n",
    "    n_alleles = acs[pops[0]].shape[1]\n",
    "    assert n_alleles == 2, 'only biallelic variants supported'\n",
    "    for pop in pops[1:]:\n",
    "        assert n_variants == acs[pop].shape[0], 'bad number of variants for pop %s' % pop\n",
    "        assert n_alleles == acs[pop].shape[1], 'bad number of alleles for pop %s' % pop\n",
    "        \n",
    "    with open(fn, 'wt', encoding='ascii') as f:\n",
    "        print(' '.join(pops), file=f)\n",
    "        for i in range(n_variants):\n",
    "            print(' '.join([','.join(map(str, acs[pop][i])) for pop in pops]), file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_and_prune(chrom, start, stop, loc_asc,\n",
    "                         n=100000, ldp_size=500, ldp_step=250, ldp_threshold=.1, ldp_n_iter=1):\n",
    "\n",
    "    # all variant positions\n",
    "    pos = allel.SortedIndex(callset_pass[chrom]['variants/POS'][:])\n",
    "    posa = pos[loc_asc]\n",
    "\n",
    "    # randomly downsample\n",
    "    if n < posa.shape[0]:\n",
    "        posds = np.random.choice(posa, n, replace=False)\n",
    "        posds.sort()\n",
    "        posds = allel.SortedIndex(posds)\n",
    "    else:\n",
    "        # skip downsampling\n",
    "        posds = posa\n",
    "    locds = pos.locate_keys(posds)    \n",
    "\n",
    "    # load genotype data\n",
    "    genotype = allel.GenotypeChunkedArray(callset_pass[chrom]['calldata/GT'])\n",
    "    gn = genotype.to_n_alt()\n",
    "\n",
    "    # prune\n",
    "    posu, gnu = ld_prune(posds, gn, size=ldp_size, step=ldp_step, threshold=ldp_threshold, n_iter=ldp_n_iter)\n",
    "    locu = pos.locate_keys(posu)\n",
    "    \n",
    "    return locu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(rname, chrom, start, stop, outgroups, segpops,\n",
    "                 n=100000, ldp_size=500, ldp_step=250, ldp_threshold=.1, ldp_n_iter=1):\n",
    "\n",
    "    # initial ascertainment\n",
    "    loc_og_asc = outgroup_ascertainment(chrom, start, stop, outgroups=outgroups)\n",
    "    loc_ig_asc = ingroup_ascertainment(chrom, start, stop, segpops=segpops)\n",
    "    loc_asc = loc_og_asc & loc_ig_asc\n",
    "    log('initial ascertainment', nnz(loc_asc))\n",
    "    \n",
    "    # downsample and prune\n",
    "    locu = downsample_and_prune(chrom, start, stop, loc_asc, \n",
    "                                n=n, ldp_size=ldp_size, ldp_step=ldp_step, \n",
    "                                ldp_threshold=ldp_threshold, ldp_n_iter=ldp_n_iter)\n",
    "    \n",
    "    # write allele counts\n",
    "    acsu = dict()\n",
    "    for pop in populations:\n",
    "        acsu[pop] = allele_counts[chrom][pop][:, :2][locu]\n",
    "    for pop in outgroups:\n",
    "        acsu[pop] = outgroup_allele_counts[chrom][pop][:, :2][locu]\n",
    "\n",
    "    outdir = 'data/treemix/seg_%s_og_%s_ldp_%s' % ('_'.join(segpops), '_'.join(outgroups), ldp_n_iter)\n",
    "    !mkdir -pv {outdir}\n",
    "    fn = os.path.join(outdir, '%s.allele_counts.txt' % rname)\n",
    "    to_treemix(acsu, fn)\n",
    "    !gzip -fv {fn}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(*msg):\n",
    "    print(' '.join(map(str, msg)), file=sys.stdout)\n",
    "    sys.stdout.flush()\n",
    "nnz = np.count_nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "outgroups = ['arab', 'quad', 'meru', 'mela', 'chri']\n",
    "segpops = ['BFcol', 'BFgam', 'AOcol', 'GAgam']\n",
    "n = 200000\n",
    "ldp_n_iter = 1\n",
    "region_X_speciation = 'X-speciation', 'X', 15000000, 24000000 \n",
    "region_X_free = 'X-free', 'X', 1, 14000000 \n",
    "region_3L_free = '3L-free', '3L', 15000000, 41000000\n",
    "region_3R_free = '3R-free', '3R', 28200000, 29200000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arab', 'chri', 'epir', 'mela', 'meru', 'quad']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(outgroup_allele_counts['2L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3R-free 3R 28200000 29200000\n",
      "outgroup ascertainment, initial 200873\n",
      "arab 190848\n",
      "quad 187297\n",
      "meru 181770\n",
      "mela 174043\n",
      "chri 103089\n",
      "ingroup ascertainment, initial 200873\n",
      "after require segregating in BFcol 61068\n",
      "after require segregating in BFgam 21946\n",
      "after require segregating in AOcol 11411\n",
      "after require segregating in GAgam 9458\n",
      "initial ascertainment 4315\n"
     ]
    }
   ],
   "source": [
    "import bcolz\n",
    "rname, chrom, start, stop = region_3R_free\n",
    "log(rname, chrom, start, stop)\n",
    "run_analysis(rname, chrom, start, stop, outgroups, segpops, n=n, ldp_n_iter=ldp_n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rname, chrom, start, stop = region_3L_free\n",
    "log(rname, chrom, start, stop)\n",
    "run_analysis(rname, chrom, start, stop, outgroups, segpops, n=n, ldp_n_iter=ldp_n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rname, chrom, start, stop = region_X_free\n",
    "log(rname, chrom, start, stop)\n",
    "run_analysis(rname, chrom, start, stop, outgroups, segpops, n=n, ldp_n_iter=ldp_n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rname, chrom, start, stop = region_X_speciation\n",
    "log(rname, chrom, start, stop)\n",
    "run_analysis(rname, chrom, start, stop, outgroups, segpops, n=n, ldp_n_iter=ldp_n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
