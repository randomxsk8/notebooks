{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for create a new outgroup dataset for phase2\n",
    "\n",
    "This notebook is structured in 5 steps:\n",
    "\n",
    "1) Loading step\n",
    "\n",
    "2) Alignment step\n",
    "\n",
    "3) Writing step\n",
    "\n",
    "4) Mapping step\n",
    "\n",
    "5) Building step\n",
    "\n",
    "\n",
    "Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run 'imports.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Loading step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading phase2 calldata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs =  gcsfs.GCSFileSystem(project='malariagen-jupyterhub', token='cloud') ## cloud connection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_path = os.path.join(\"ag1000g-release/phase2.AR1/variation/main/zarr/all/ag1000g.phase2.ar1\")  ## Adding phase2 genotype path \n",
    "gcsmap = gcsfs.mapping.GCSMap(geno_path, gcs=gcs) ## link callset\n",
    "callset= zarr.Group(gcsmap, read_only=True) ## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_bi_path = os.path.join(\"ag1000g-release/phase2.AR1/variation/main/zarr/biallelic/ag1000g.phase2.ar1.pass.biallelic\")  ## Adding phase2 genotype path \n",
    "gcsmap_bi = gcsfs.mapping.GCSMap(geno_bi_path, gcs=gcs) ## link callset\n",
    "callset_biallel= zarr.Group(gcsmap_bi, read_only=True) ## read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ingroup calldata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingroup_species = 'arab','meru', 'mela', 'quad'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingroup_callset_fn_template = '/bucket/outgroup/{species}_ref_ug_vqsr_cnvrt_sort.h5'\n",
    "agc_callsets = {species: h5py.File(ingroup_callset_fn_template.format(species=species), mode='r')\n",
    "                    for species in ingroup_species}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test mela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agc_callsets['mela']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading outgroup calldata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outgroup_species = ['chri', 'epir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outgroup_variants_fn_template = '/bucket/{species}_fake_cnvrt_sort.vcf.gz.vcfnp_cache/variants.{chrom}.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Align step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align ingroup calldata to the phase2 calldata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_ingroup_ac(chrom, species):\n",
    "    \n",
    "    # load Ag1000G variant positions and alternate alleles\n",
    "    variants = callset[chrom]['variants']\n",
    "    pos = allel.SortedIndex(variants['POS'][:], copy=False)\n",
    "    alt = variants['ALT'][:]\n",
    "    \n",
    "    # load ingroup variant positions and alternate alleles\n",
    "    variants_other = agc_callsets[species][chrom]['variants']\n",
    "    pos_other = allel.SortedIndex(variants_other['POS'][:], copy=False)\n",
    "    alt_other = agc_callsets[species][chrom]['variants']['ALT'][:]\n",
    "    \n",
    "    # locate intersection between callsets\n",
    "    loc_isec, loc_other_isec = pos.locate_intersection(pos_other)\n",
    "    # exclude duplicates\n",
    "    loc_other_dup = pos_other == np.roll(pos_other, 1)\n",
    "    loc_other_isec &= ~loc_other_dup\n",
    "    assert nnz(loc_isec) == nnz(loc_other_isec)\n",
    "    log(pos.size, 'variants in Ag1000G')\n",
    "    log(nnz(loc_isec), 'variants in intersection')\n",
    "    \n",
    "    # filter data to the intersection\n",
    "    alt_isec = alt[loc_isec]\n",
    "    alt_other_isec = alt_other[loc_other_isec]\n",
    "    \n",
    "    # load ingroup genotypes and count alleles\n",
    "    genotype_other_isec = allel.GenotypeChunkedArray(agc_callsets[species][chrom]['calldata']['genotype']).compress(loc_other_isec, axis=0)\n",
    "    ac_other_isec = genotype_other_isec.count_alleles()[:]\n",
    "\n",
    "    # setup array to store ingroup allele counts with alleles remapped to Ag1000G\n",
    "    n_variants_isec = nnz(loc_isec)\n",
    "    ac_am = np.zeros((n_variants_isec, 4), dtype='i4')\n",
    "\n",
    "    # fill in reference allele counts\n",
    "    ac_am[:, 0] = ac_other_isec[:, 0]\n",
    "    \n",
    "    # fill in alternate allele counts\n",
    "    loc_a1 = alt_isec[:, 0] == alt_other_isec\n",
    "    loc_a2 = alt_isec[:, 1] == alt_other_isec\n",
    "    loc_a3 = alt_isec[:, 2] == alt_other_isec\n",
    "    ac_am[loc_a1, 1] = ac_other_isec[loc_a1, 1]\n",
    "    ac_am[loc_a2, 2] = ac_other_isec[loc_a2, 1]\n",
    "    ac_am[loc_a3, 3] = ac_other_isec[loc_a3, 1]    \n",
    "    \n",
    "    # finally extend to all Ag1000G variant positions\n",
    "    ac_aligned = np.zeros((pos.shape[0], 4), dtype='i4')\n",
    "    ac_aligned[loc_isec] = ac_am\n",
    "    for i in range(4):\n",
    "        log(i, nnz(ac_aligned[:, i]))\n",
    "    \n",
    "    return ac_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18167056 variants in Ag1000G\n",
      "13772829 variants in intersection\n",
      "0 12797186\n",
      "1 627764\n",
      "2 176462\n",
      "3 19444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_aligned = align_ingroup_ac('3L', 'mela')\n",
    "ac_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align outgroup calldata to the phase2 calldata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_outgroup_ac(chrom, species):\n",
    "\n",
    "    # load Ag1000G variant positions and alternate alleles\n",
    "    variants = callset[chrom]['variants']\n",
    "    pos = allel.SortedIndex(variants['POS'][:], copy=False)\n",
    "    alt = variants['ALT'][:]\n",
    "    \n",
    "    # load outgroup variant positions and alternate alleles\n",
    "    variants_other = np.load(outgroup_variants_fn_template.format(species=species, chrom=chrom), mmap_mode='r')\n",
    "    pos_other = allel.SortedIndex(variants_other['POS'], copy=False)\n",
    "    alt_other = variants_other['ALT']\n",
    "\n",
    "    # locate intersection between callsets\n",
    "    loc_isec, loc_other_isec = pos.locate_intersection(pos_other)\n",
    "    # exclude duplicates\n",
    "    loc_other_dup = pos_other == np.roll(pos_other, 1)\n",
    "    loc_other_isec &= ~loc_other_dup\n",
    "    assert nnz(loc_isec) == nnz(loc_other_isec)\n",
    "    log(pos.size, 'variants in Ag1000G')\n",
    "    log(nnz(loc_isec), 'variants in intersection')\n",
    "\n",
    "    # filter data to the intersection\n",
    "    alt_isec = alt[loc_isec]\n",
    "    alt_other_isec = alt_other[loc_other_isec]\n",
    "\n",
    "    # setup array to store outgroup allele counts with alleles remapped to Ag1000G\n",
    "    n_variants_isec = nnz(loc_isec)\n",
    "    ac_am = np.zeros((n_variants_isec, 4), dtype='i4')\n",
    "    \n",
    "    # reference allele observed\n",
    "    loc_ref = alt_other_isec == b'.'\n",
    "    loc_a1 = alt_isec[:, 0] == alt_other_isec\n",
    "    loc_a2 = alt_isec[:, 1] == alt_other_isec\n",
    "    loc_a3 = alt_isec[:, 2] == alt_other_isec\n",
    "    ac_am[loc_ref, 0] = 1\n",
    "    ac_am[loc_a1, 1] = 1\n",
    "    ac_am[loc_a2, 2] = 1\n",
    "    ac_am[loc_a3, 3] = 1\n",
    "\n",
    "    # finally extend to all Ag1000G variant positions\n",
    "    ac_aligned = np.zeros((pos.shape[0], 4), dtype='i4')\n",
    "    ac_aligned[loc_isec] = ac_am\n",
    "    for i in range(4):\n",
    "        log(i, nnz(ac_aligned[:, i]))\n",
    "    \n",
    "    return ac_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "christyi try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18167056 variants in Ag1000G\n",
      "9887983 variants in intersection\n",
      "0 7203267\n",
      "1 1189266\n",
      "2 300458\n",
      "3 36233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_aligned = align_outgroup_ac('3L', 'chri')\n",
    "ac_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Writing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the align on a new hdf5 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/outgroup_allele_counts_phase2.h5',\n",
    "               mode='a') as outgroup_allele_counts:\n",
    "    for chrom in chromosomes:\n",
    "        h5g = outgroup_allele_counts.require_group(chrom)\n",
    "        for species in ingroup_species:\n",
    "            if species in h5g:\n",
    "                log(chrom, species, 'skipping')\n",
    "            else:\n",
    "                log(chrom, species, 'building')\n",
    "                ac_aligned = align_ingroup_ac(chrom, species)\n",
    "                h5d = h5g.create_dataset(species, data=ac_aligned, chunks=True)\n",
    "\n",
    "        for species in outgroup_species:\n",
    "            if species in h5g:\n",
    "                log(chrom, species, 'skipping')\n",
    "            else:\n",
    "                log(chrom, species, 'building')\n",
    "                ac_aligned = align_outgroup_ac(chrom, species)\n",
    "                h5d = h5g.create_dataset(species, data=ac_aligned, chunks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Mapping step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['2L', '2R', '3L', '3R', 'X']>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calldata_out= h5py.File('data/outgroup_allele_counts_phase2.h5', mode='r')\n",
    "calldata_out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"chri\": shape (11524923, 4), type \"<i4\">"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calldata_out['2L']['chri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_map(species, chrom):\n",
    "    \n",
    "        for chrom in chromosomes:\n",
    "\n",
    "            pos_all = allel.SortedIndex(callset[chrom][\"variants/POS\"][:])\n",
    "            pos_bi = allel.SortedIndex(callset_biallel[chrom][\"variants/POS\"])\n",
    "            loc1, loc2 = pos_bi.locate_intersection(pos_all)\n",
    "            pos_p2_sel = pos_bi[loc1]\n",
    "            pos_p1_sel = pos_all[loc2]\n",
    "            variants_all = allel.VariantChunkedTable(callset[chrom][\"variants\"], \n",
    "                                                 names=['POS', 'REF', 'ALT', 'DP', 'MQ', 'QD', 'numalt'],\n",
    "                                                 index='POS')\n",
    "            variants_bi = allel.VariantChunkedTable(callset_biallel[chrom][\"variants\"], \n",
    "                                                 names=['POS', 'REF', 'ALT', 'DP', 'MQ', 'QD', 'numalt'],\n",
    "                                                 index='POS')\n",
    "\n",
    "            variants_all_filt = variants_all.compress(loc2)\n",
    "            phase2_all_ref = variants_all_filt[\"REF\"][:]\n",
    "            phase2_all_alt = variants_all_filt[\"ALT\"][:]\n",
    "\n",
    "            variants_bi_filt = variants_bi.compress(loc1)\n",
    "            phase2_bi_ref = variants_bi_filt[\"REF\"][:]\n",
    "            phase2_bi_alt = variants_bi_filt[\"ALT\"][:]\n",
    "\n",
    "            phase2_bi_refalt = np.column_stack([phase2_bi_ref, phase2_bi_alt])\n",
    "            mapping = allel.create_allele_mapping(phase2_all_ref, phase2_all_alt, phase2_bi_refalt)\n",
    "            calldata_outgroup= h5py.File('data/outgroup_allele_counts_phase2.h5', mode='r')\n",
    "            calldata_out_pop = calldata_outgroup[chrom][species]\n",
    "            ac_out_pop = allel.AlleleCountsArray(calldata_out_pop)\n",
    "            ac_out_pop = ac_out_pop.compress(loc2)\n",
    "            pop_map_ac = ac_out_pop.map_alleles(mapping)\n",
    "\n",
    "        return pop_map_ac   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chri_2R = out_map('chri' , '2R')\n",
    "chri_2L = out_map('chri' , '2L')\n",
    "chri_3R = out_map('chri' , '3R')\n",
    "chri_3L = out_map('chri' , '3L')\n",
    "chri_X = out_map('chri' , 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epir_2R = out_map('epir' , '2R')\n",
    "epir_2L = out_map('epir' , '2L')\n",
    "epir_3R = out_map('epir' , '3R')\n",
    "epir_3L = out_map('epir' , '3L')\n",
    "epir_X = out_map('epir' , 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arab_2R = out_map('arab' , '2R')\n",
    "arab_2L = out_map('arab' , '2L')\n",
    "arab_3R = out_map('arab' , '3R')\n",
    "arab_3L = out_map('arab' , '3L')\n",
    "arab_X = out_map('arab' , 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meru_2R = out_map('meru' , '2R')\n",
    "meru_2L = out_map('meru' , '2L')\n",
    "meru_3R = out_map('meru' , '3R')\n",
    "meru_3L = out_map('meru' , '3L')\n",
    "meru_X = out_map('meru' , 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mela_2R = out_map('mela' , '2R')\n",
    "mela_2L = out_map('mela' , '2L')\n",
    "mela_3R = out_map('mela' , '3R')\n",
    "mela_3L = out_map('mela' , '3L')\n",
    "mela_X = out_map('mela' , 'X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_2R = out_map('quad' , '2R')\n",
    "quad_2L = out_map('quad' , '2L')\n",
    "quad_3R = out_map('quad' , '3R')\n",
    "quad_3L = out_map('quad' , '3L')\n",
    "quad_X = out_map('quad' , 'X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Writing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = zarr.open('outgroup_alleles_phase2.zarr', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foo = root.create_group('foo')\n",
    "#bar = foo.create_dataset('bar', data=my_array)\n",
    "# shortcuts\n",
    "bar = root.create_dataset('2R/chri', data=chri_2R)\n",
    "bar = root.create_dataset('2R/epir', data=epir_2R)\n",
    "bar = root.create_dataset('2R/mela', data=mela_2R)\n",
    "bar = root.create_dataset('2R/meru', data=meru_2R)\n",
    "bar = root.create_dataset('2R/arab', data=arab_2R)\n",
    "bar = root.create_dataset('2R/quad', data=quad_2R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = root.create_dataset('2L/chri', data=chri_2L)\n",
    "bar = root.create_dataset('2L/epir', data=epir_2L)\n",
    "bar = root.create_dataset('2L/mela', data=mela_2L)\n",
    "bar = root.create_dataset('2L/meru', data=meru_2L)\n",
    "bar = root.create_dataset('2L/arab', data=arab_2L)\n",
    "bar = root.create_dataset('2L/quad', data=quad_2L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = root.create_dataset('3R/chri', data=chri_3R)\n",
    "bar = root.create_dataset('3R/epir', data=epir_3R)\n",
    "bar = root.create_dataset('3R/mela', data=mela_3R)\n",
    "bar = root.create_dataset('3R/meru', data=meru_3R)\n",
    "bar = root.create_dataset('3R/arab', data=arab_3R)\n",
    "bar = root.create_dataset('3R/quad', data=quad_3R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = root.create_dataset('3L/chri', data=chri_3L)\n",
    "bar = root.create_dataset('3L/epir', data=epir_3L)\n",
    "bar = root.create_dataset('3L/mela', data=mela_3L)\n",
    "bar = root.create_dataset('3L/meru', data=meru_3L)\n",
    "bar = root.create_dataset('3L/arab', data=arab_3L)\n",
    "bar = root.create_dataset('3L/quad', data=quad_3L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = root.create_dataset('X/chri', data=chri_X)\n",
    "bar = root.create_dataset('X/epir', data=epir_X)\n",
    "bar = root.create_dataset('X/mela', data=mela_X)\n",
    "bar = root.create_dataset('X/meru', data=meru_X)\n",
    "bar = root.create_dataset('X/arab', data=arab_X)\n",
    "bar = root.create_dataset('X/quad', data=quad_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data again\n",
    "my_array= root['2L/arab'][:]\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allel.AlleleCountsArray(root['2L/arab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allel.AlleleCountsArray(calldata_out['2L/arab'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
