{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 182)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj = (fs_fw.sample_sizes[0], fs_fw.sample_sizes[1])\n",
    "proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_ids=[\"GM\", \"GW\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spectrum([[-- 142068.0 37092.0 ... 0.0 0.0 0.0]\n",
       " [39777.0 17181.0 9725.0 ... 0.0 0.0 0.0]\n",
       " [14933.0 8036.0 5498.0 ... 0.0 0.0 0.0]\n",
       " ...\n",
       " [0.0 0.0 0.0 ... 0.0 2.0 1.0]\n",
       " [0.0 0.0 0.0 ... 0.0 2.0 3.0]\n",
       " [0.0 0.0 0.0 ... 3.0 8.0 --]], folded=False, pop_ids=['GM', 'GW'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_fw = dadi.Spectrum(np.load(\"dadi/fs_2_pops/GM_GW.npy\"), pop_ids = ['GM', 'GW'])\n",
    "fs_fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================\n",
      "\n",
      "Data for site frequency spectrum:\n",
      "\n",
      "Projection: (130, 182)\n",
      "Sample sizes: [130 182]\n",
      "Sum of SFS: 446514.0\n",
      "\n",
      "============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n============================================================================\")\n",
    "print(\"\\nData for site frequency spectrum:\\n\")\n",
    "print(\"Projection: {}\".format(proj))\n",
    "print(\"Sample sizes: {}\".format(fs_fw.sample_sizes))\n",
    "print(\"Sum of SFS: {}\".format(np.around(fs_fw.S(), 2)))\n",
    "print(\"\\n============================================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy\n",
    "import dadi\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_params(param_number, in_params=None, in_upper=None, in_lower=None):\n",
    "    #--------------------------------------------------------------------------------------\n",
    "    # function to correctly deal with parameters and bounds, if none were provided, generate them automatically\n",
    "    \n",
    "    # Arguments\n",
    "    # param_number: number of parameters in the model selected (can count in params line for the model)\n",
    "    # in_params: a list of parameter values \n",
    "    # in_upper: a list of upper bound values\n",
    "    # in_lower: a list of lower bound values\n",
    "    #--------------------------------------------------------------------------------------\n",
    "    param_number = int(param_number)\n",
    "    \n",
    "    #param set\n",
    "    if in_params is None:\n",
    "        params = [1] * param_number\n",
    "    elif len(in_params) != param_number:\n",
    "        raise ValueError(\"Set of input parameters does not contain the correct number of values: {}\".format(param_number))\n",
    "    else:\n",
    "        params = in_params\n",
    "        \n",
    "    #upper bound    \n",
    "    if in_upper is None:\n",
    "        upper_bound = [30] * param_number\n",
    "    elif len(in_upper) != param_number:\n",
    "        raise ValueError(\"Upper bound set for parameters does not contain the correct number of values: {}\".format(param_number))\n",
    "    else:\n",
    "        upper_bound = in_upper\n",
    "        \n",
    "    #lower bounds\n",
    "    if in_lower is None:\n",
    "        lower_bound = [0.01] * param_number\n",
    "    elif len(in_lower) != param_number:\n",
    "        raise ValueError(\"Lower bound set for parameters does not contain the correct number of values: {}\".format(param_number))\n",
    "    else:\n",
    "        lower_bound = in_lower\n",
    "        \n",
    "    return params, upper_bound, lower_bound\n",
    "\n",
    "def parse_opt_settings(rounds, reps=None, maxiters=None, folds=None):\n",
    "    #--------------------------------------------------------------------------------------\n",
    "    # function to correctly deal with replicate numbers, maxiter and fold args\n",
    "    \n",
    "    # Arguments\n",
    "    # rounds: number of optimization rounds to perform\n",
    "    # reps: a list of integers controlling the number of replicates in each of three optimization rounds\n",
    "    # maxiters: a list of integers controlling the maxiter argument in each of three optimization rounds\n",
    "    # folds: a list of integers controlling the fold argument when perturbing input parameter values\n",
    "    #--------------------------------------------------------------------------------------\n",
    "    rounds = int(rounds)\n",
    "    \n",
    "    #rep set\n",
    "    #create scheme where final replicates will be 20, and all previous 10\n",
    "    if reps is None:\n",
    "        if rounds >= 2:\n",
    "            reps_list = [10] * (rounds-1)\n",
    "            reps_list.insert(len(reps_list),20)\n",
    "        else:\n",
    "            reps_list = [10] * rounds\n",
    "    elif len(reps) != rounds:\n",
    "        raise ValueError(\"List length of replicate values does match the number of rounds: {}\".format(rounds))\n",
    "    else:\n",
    "        reps_list = reps\n",
    "        \n",
    "    #maxiters   \n",
    "    if maxiters is None:\n",
    "        maxiters_list = [5] * rounds\n",
    "    elif len(maxiters) != rounds:\n",
    "        raise ValueError(\"List length of maxiter values does match the number of rounds: {}\".format(rounds))\n",
    "    else:\n",
    "        maxiters_list = maxiters\n",
    "        \n",
    "    #folds\n",
    "    #create scheme so if rounds is greater than three, will always end with two fold and then one fold\n",
    "    if folds is None:\n",
    "        if rounds >= 3:\n",
    "            folds_list = [3] * (rounds-2)\n",
    "            folds_list.insert(len(folds_list),2)\n",
    "            folds_list.insert(len(folds_list),1)\n",
    "        elif rounds == 2:\n",
    "            folds_list = [2] * (rounds-1)\n",
    "            folds_list.insert(len(folds_list),1)\n",
    "        else:\n",
    "            folds_list = [2] * rounds\n",
    "    elif len(folds) != rounds:\n",
    "        raise ValueError(\"List length of fold values does match the number of rounds: {}\".format(rounds))\n",
    "    else:\n",
    "        folds_list = folds\n",
    "        \n",
    "    return reps_list, maxiters_list, folds_list\n",
    "\n",
    "def collect_results(fs, sim_model, params_opt, roundrep, fs_folded):\n",
    "    #--------------------------------------------------------------------------------------\n",
    "    # gather up a bunch of results, return a list = [roundnum_repnum, log-likelihood, AIC, chi^2 test stat, theta, parameter values] \n",
    "    \n",
    "    # Arguments\n",
    "    # fs: spectrum object name\n",
    "    # sim_model: model fit with optimized parameters\n",
    "    # params_opt: list of the optimized parameters\n",
    "    # fs_folded: a Boolean (True, False) for whether empirical spectrum is folded or not\n",
    "    #--------------------------------------------------------------------------------------\n",
    "\n",
    "    #calculate likelihood\n",
    "    ll = dadi.Inference.ll_multinom(sim_model, fs)\n",
    "    ll = numpy.around(ll, 2)\n",
    "    print(\"\\t\\t\\tLikelihood = {:,}\".format(ll))\n",
    "\n",
    "    #calculate AIC \n",
    "    aic = ( -2*( float(ll))) + (2*len(params_opt))\n",
    "    print(\"\\t\\t\\tAIC = {:,}\".format(aic))\n",
    "\n",
    "    #calculate theta\n",
    "    theta = dadi.Inference.optimal_sfs_scaling(sim_model, fs)\n",
    "    theta = numpy.around(theta, 2)\n",
    "    print(\"\\t\\t\\tTheta = {:,}\".format(theta))\n",
    "\n",
    "    #get Chi^2\n",
    "    scaled_sim_model = sim_model*theta\n",
    "    if fs_folded is True:\n",
    "        #calculate Chi^2 statistic for folded\n",
    "        folded_sim_model = scaled_sim_model.fold()\n",
    "        chi2 = numpy.sum((folded_sim_model - fs)**2/folded_sim_model)\n",
    "        chi2 = numpy.around(chi2, 2)\n",
    "    elif fs_folded is False:\n",
    "        #calculate Chi^2 statistic for unfolded\n",
    "        chi2 = numpy.sum((scaled_sim_model - fs)**2/scaled_sim_model)\n",
    "        chi2 = numpy.around(chi2, 2)\n",
    "    print(\"\\t\\t\\tChi-Squared = {:,}\".format(chi2))        \n",
    "\n",
    "    #store key results in temporary sublist, append to larger results list\n",
    "    temp_results = [roundrep, ll, aic, chi2, theta, params_opt]\n",
    "\n",
    "    return temp_results\n",
    "\n",
    "def write_log(outfile, model_name, rep_results, roundrep):\n",
    "    #--------------------------------------------------------------------------------------\n",
    "    #reproduce replicate log to bigger log file, because constantly re-written\n",
    "    \n",
    "    # Arguments =\n",
    "    # outfile: prefix for output naming\n",
    "    # model_name: a label to slap on the output files; ex. \"no_mig\"\n",
    "    # rep_results: the list returned by collect_results function: [roundnum_repnum, log-likelihood, AIC, chi^2 test stat, theta, parameter values]\n",
    "    # roundrep: name of replicate (ex, \"Round_1_Replicate_10\")\n",
    "    #--------------------------------------------------------------------------------------\n",
    "    fh_log = open(\"{0}.{1}.log.txt\".format(outfile, model_name), 'a')\n",
    "    fh_log.write(\"\\n{}\\n\".format(roundrep))\n",
    "    templogname = \"{}.log.txt\".format(model_name)\n",
    "    try:\n",
    "        fh_templog = open(templogname, 'r')\n",
    "        for line in fh_templog:\n",
    "            fh_log.write(line)\n",
    "        fh_templog.close()\n",
    "    except IOError:\n",
    "        print(\"Nothing written to log file this replicate...\")\n",
    "    fh_log.write(\"likelihood = {}\\n\".format(rep_results[1]))\n",
    "    fh_log.write(\"theta = {}\\n\".format(rep_results[4]))\n",
    "    fh_log.write(\"Optimized parameters = {}\\n\".format(rep_results[5]))\n",
    "    fh_log.close()\n",
    "\n",
    "def Optimize_Routine(fs, pts, outfile, model_name, func, rounds, param_number, fs_folded=True,\n",
    "                         reps=None, maxiters=None, folds=None, in_params=None,\n",
    "                         in_upper=None, in_lower=None, param_labels=\" \"):\n",
    "    #--------------------------------------------------------------------------------------\n",
    "    # Mandatory Arguments =\n",
    "    #(1) fs:  spectrum object name\n",
    "    #(2) pts: grid size for extrapolation, list of three values\n",
    "    #(3) outfile:  prefix for output naming\n",
    "    #(4) model_name: a label to slap on the output files; ex. \"no_mig\"\n",
    "    #(5) func: access the model function from within 'moments_optimize.py' or from a separate python model script, ex. Models_2D.no_mig\n",
    "    #(6) rounds: number of optimization rounds to perform\n",
    "    #(7) param_number: number of parameters in the model selected (can count in params line for the model)\n",
    "    #(8) fs_folded: A Boolean value (True or False) indicating whether the empirical fs is folded (True) or not (False). Default is True.\n",
    "\n",
    "    # Optional Arguments =\n",
    "    #(9) reps: a list of integers controlling the number of replicates in each of three optimization rounds\n",
    "    #(10) maxiters: a list of integers controlling the maxiter argument in each of three optimization rounds\n",
    "    #(11) folds: a list of integers controlling the fold argument when perturbing input parameter values\n",
    "    #(12) in_params: a list of parameter values \n",
    "    #(13) in_upper: a list of upper bound values\n",
    "    #(14) in_lower: a list of lower bound values\n",
    "    #(15) param_labels: list of labels for parameters that will be written to the output file to keep track of their order\n",
    "    #--------------------------------------------------------------------------------------\n",
    "\n",
    "    #call function that determines if our params and bounds have been set or need to be generated for us\n",
    "    params, upper_bound, lower_bound = parse_params(param_number, in_params, in_upper, in_lower)\n",
    "\n",
    "    #call function that determines if our replicates, maxiter, and fold have been set or need to be generated for us\n",
    "    reps_list, maxiters_list, folds_list = parse_opt_settings(rounds, reps, maxiters, folds)\n",
    "    \n",
    "    print(\"\\n\\n============================================================================\"\n",
    "              \"\\nModel {}\\n============================================================================\\n\\n\".format(model_name))\n",
    "\n",
    "    #start keeping track of time it takes to complete optimizations for this model\n",
    "    tbr = datetime.now()\n",
    "    \n",
    "    # We need an output file that will store all summary info for each replicate, across rounds\n",
    "    outname = \"{0}.{1}.optimized.txt\".format(outfile, model_name)\n",
    "    with open(outname, 'a') as fh_out:\n",
    "        fh_out.write(\"Model\\tReplicate\\tlog-likelihood\\tAIC\\tchi-squared\\ttheta\\toptimized_params({})\\n\".format(param_labels))\n",
    "        \n",
    "    #Create list to store sublists of [roundnum_repnum, log-likelihood, AIC, chi^2 test stat, theta, parameter values] for every replicate\n",
    "    results_list = []\n",
    "    \n",
    "    #for every round, execute the assigned number of replicates with other round-defined args (maxiter, fold, best_params)\n",
    "    rounds = int(rounds)\n",
    "    for r in range(rounds):\n",
    "        print(\"\\tBeginning Optimizations for Round {}:\".format(r+1))\n",
    "       \n",
    "        #make sure first round params are assigned (either user input or auto generated)\n",
    "        if r == int(0):\n",
    "            best_params = params\n",
    "        #and that all subsequent rounds use the params from a previous best scoring replicate\n",
    "        else:\n",
    "            best_params = results_list[0][5]\n",
    "\n",
    "        #perform an optimization routine for each rep number in this round number\n",
    "        for rep in range(1, (reps_list[r]+1) ):\n",
    "            print(\"\\n\\t\\tRound {0} Replicate {1} of {2}:\".format(r+1, rep, (reps_list[r])))\n",
    "            \n",
    "            #keep track of start time for rep\n",
    "            tb_rep = datetime.now()\n",
    "            \n",
    "            #create an extrapolating function \n",
    "            func_exec = dadi.Numerics.make_extrap_log_func(func)\n",
    "            \n",
    "            #perturb starting parameters\n",
    "            params_perturbed = dadi.Misc.perturb_params(best_params, fold=folds_list[r],\n",
    "                                                            upper_bound=upper_bound, lower_bound=lower_bound)\n",
    "            \n",
    "            print(\"\\n\\t\\t\\tStarting parameters = [{}]\".format(\", \".join([str(numpy.around(x, 6)) for x in params_perturbed])))\n",
    "            \n",
    "            #optimize from perturbed parameters\n",
    "            params_opt = dadi.Inference.optimize_log_fmin(params_perturbed, fs, func_exec, pts,\n",
    "                                                              lower_bound=lower_bound, upper_bound=upper_bound,\n",
    "                                                              verbose=1, maxiter=maxiters_list[r],\n",
    "                                                              output_file = \"{}.log.txt\".format(model_name))\n",
    "            \n",
    "            print(\"\\t\\t\\tOptimized parameters =[{}]\\n\".format(\", \".join([str(numpy.around(x, 6)) for x in params_opt[0]])))\n",
    "            \n",
    "            #simulate the model with the optimized parameters\n",
    "            sim_model = func_exec(params_opt[0], fs.sample_sizes, pts)\n",
    "\n",
    "            #collect results into a list using function above - [roundnum_repnum, log-likelihood, AIC, chi^2 test stat, theta, parameter values]\n",
    "            roundrep = \"Round_{0}_Replicate_{1}\".format(r+1, rep)\n",
    "            rep_results = collect_results(fs, sim_model, params_opt[0], roundrep, fs_folded)\n",
    "            \n",
    "            #reproduce replicate log to bigger log file, because constantly re-written\n",
    "            write_log(outfile, model_name, rep_results, roundrep)\n",
    "            \n",
    "            #append results from this sim to larger list\n",
    "            results_list.append(rep_results)\n",
    "            \n",
    "            #write all this info to our main results file\n",
    "            with open(outname, 'a') as fh_out:\n",
    "                #join the param values together with commas\n",
    "                easy_p = \",\".join([str(numpy.around(x, 4)) for x in rep_results[5]])\n",
    "                fh_out.write(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\n\".format(model_name, rep_results[0],\n",
    "                                                                              rep_results[1], rep_results[2],\n",
    "                                                                              rep_results[3], rep_results[4],\n",
    "                                                                              easy_p))\n",
    "\n",
    "            #calculate elapsed time for replicate\n",
    "            tf_rep = datetime.now()\n",
    "            te_rep = tf_rep - tb_rep\n",
    "            print(\"\\n\\t\\t\\tReplicate time: {0} (H:M:S)\\n\".format(te_rep))\n",
    "\n",
    "        #Now that this round is over, sort results in order of likelihood score\n",
    "        #we'll use the parameters from the best rep to start the next round as the loop continues\n",
    "        results_list.sort(key=lambda x: float(x[1]), reverse=True)\n",
    "        print(\"\\n\\t----------------------------------------------\\n\"\n",
    "                  \"\\tBest replicate: {0}\\n\"\n",
    "                  \"\\t\\tLikelihood = {1:,}\\n\\t\\tAIC = {2:,}\\n\"\n",
    "                  \"\\t\\tChi-Squared = {3:,}\\n\\t\\tParams = [{4}]\\n\"\n",
    "                  \"\\t----------------------------------------------\\n\\n\".format(results_list[0][0],\n",
    "                                                                              results_list[0][1],\n",
    "                                                                              results_list[0][2],\n",
    "                                                                              results_list[0][3],\n",
    "                                                                              \", \".join([str(numpy.around(x, 4)) for x in rep_results[5]])))\n",
    "\n",
    "    #Now that all rounds are over, calculate elapsed time for the whole model\n",
    "    tfr = datetime.now()\n",
    "    ter = tfr - tbr\n",
    "    print(\"\\nAnalysis Time for Model '{0}': {1} (H:M:S)\\n\\n\"\n",
    "              \"============================================================================\".format(model_name, ter))\n",
    "\n",
    "    #cleanup file\n",
    "    os.remove(\"{}.log.txt\".format(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"_\".join(pop_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140, 150, 160]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts = [proj[0] + 10, proj[0] + 20, proj[0] + 30]\n",
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = [10,20,30,40]\n",
    "maxiters = [3,5,10,15]\n",
    "folds = [3,2,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_folded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Models_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================================================================\n",
      "Model sec_contact_asym_mig\n",
      "============================================================================\n",
      "\n",
      "\n",
      "\tBeginning Optimizations for Round 1:\n",
      "\n",
      "\t\tRound 1 Replicate 1 of 10:\n",
      "\n",
      "\t\t\tStarting parameters = [6.645857, 0.96076, 3.063908, 3.980284, 0.249376, 0.95485]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tOptimized parameters =[6.645857, 0.96076, 3.063908, 4.264909, 0.249376, 0.95485]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tLikelihood = -303,054.5\n",
      "\t\t\tAIC = 606,121.0\n",
      "\t\t\tTheta = 19,648.86\n",
      "\t\t\tChi-Squared = 890,321.16\n",
      "\n",
      "\t\t\tReplicate time: 0:01:46.021423 (H:M:S)\n",
      "\n",
      "\n",
      "\t\tRound 1 Replicate 2 of 10:\n",
      "\n",
      "\t\t\tStarting parameters = [5.904697, 0.7231, 3.179025, 0.646834, 6.881345, 4.554709]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tOptimized parameters =[4.943993, 0.717263, 3.272286, 0.639827, 7.221296, 4.730664]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tLikelihood = -521,958.46\n",
      "\t\t\tAIC = 1,043,928.92\n",
      "\t\t\tTheta = 26,723.66\n",
      "\t\t\tChi-Squared = 1,825,154.63\n",
      "\n",
      "\t\t\tReplicate time: 0:07:35.253110 (H:M:S)\n",
      "\n",
      "\n",
      "\t\tRound 1 Replicate 3 of 10:\n",
      "\n",
      "\t\t\tStarting parameters = [2.247929, 7.632732, 3.540558, 0.417859, 0.395709, 0.376807]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tOptimized parameters =[2.30945, 8.167755, 3.692956, 0.427075, 0.383668, 0.412073]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tLikelihood = -90,025.91\n",
      "\t\t\tAIC = 180,063.82\n",
      "\t\t\tTheta = 14,825.87\n",
      "\t\t\tChi-Squared = 146,351.59\n",
      "\n",
      "\t\t\tReplicate time: 0:00:53.369785 (H:M:S)\n",
      "\n",
      "\n",
      "\t\tRound 1 Replicate 4 of 10:\n",
      "\n",
      "\t\t\tStarting parameters = [5.704539, 0.288689, 4.504659, 1.620162, 0.157787, 5.347752]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n",
      "WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.\n"
     ]
    }
   ],
   "source": [
    "Optimize_Routine(fs_fw, pts, prefix, \"sec_contact_asym_mig\", Models_2D.sec_contact_asym_mig, rounds, 6, fs_folded=fs_folded,\n",
    "                                        reps=reps, maxiters=maxiters, folds=folds, param_labels = \" nu1, nu2, m12, m21, T1, T2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------\n",
    "Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../output_files/\") \n",
    "  \n",
    "print(\"Directory changed\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "usage: python Summarize_Outputs.py [full path to directory with results files]\n",
    "\n",
    "example: python Summarize_Outputs.py users/dan/moments_analyses/results/\n",
    "\n",
    "The purpose of this script is to make sense of the results files\n",
    "that are produced after optimizations have been run on multiple\n",
    "models, as there will be an output file for every model included\n",
    "that is filled with many replicates across several rounds.\n",
    "\n",
    "Two summary files will be produced:\n",
    "1. Results_Summary_Extended.txt\n",
    "    This contains the top five replicates for each results file, with all the information\n",
    "    including: \"Model\"\t\"Replicate\"\t\"log-likelihood\"\t\"AIC\"\t\"chi-squared\"\t\"theta\"\t\"optimized_params\"\n",
    "\n",
    "2. Results_Summary_Short.txt\n",
    "    This is essentially a simplified version of the above file, and only contains the\n",
    "    top scoring replicate per model and it is already sorted in order of AIC.\n",
    "\n",
    "You should probably inspect that the top-scoring replicates were ERROR-FREE. \n",
    "Often errors are logged on screen and log-likelihoods are still produced.\n",
    "\n",
    "-------------------------\n",
    "Written for Python 2.7 and 3.7\n",
    "No dependencies\n",
    "-------------------------\n",
    "\n",
    "Daniel Portik\n",
    "daniel.portik@gmail.com\n",
    "https://github.com/dportik\n",
    "Updated September 2019\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#===========================================================================\n",
    "file_dir = \"../output_files/\"\n",
    "os.chdir(file_dir)\n",
    "\n",
    "#check if summary files already exist in output directory\n",
    "results = sorted([os.path.abspath(f) for f in os.listdir(file_dir) if f.startswith(\"Results_Summary\")])\n",
    "if results:\n",
    "    raise ValueError(\"\\n\\n\\nWARNING: Summary files are already located in the directory specified.\"\n",
    "                         \" Please remove them before running this script.\\n\\n\")\n",
    "    \n",
    "\n",
    "#initiate empty lists that we will fill with summary information\n",
    "summary_list = []\n",
    "simple_list = []\n",
    "\n",
    "#list comprehension to find output files\n",
    "flist = sorted([os.path.abspath(f) for f in os.listdir(file_dir) if f.endswith(\"optimized.txt\")])\n",
    "\n",
    "#do tasks depending on whether files located or not\n",
    "if flist:\n",
    "    print(\"\\n\\nFound {} output files to summarize:\".format(len(flist)))\n",
    "    for f in flist:\n",
    "        print(\"\\t{}\".format(f.split('/')[-1]))\n",
    "else:\n",
    "    print(\"\\n\\nFound {} output files to summarize!\\n\\n\".format(len(flist)))\n",
    "    print(\"Please check to make sure the output files end with '.optimized.txt' and are\"\n",
    "              \"located in the directory specified:\\n\\t{}\".format(file_dir))\n",
    "\n",
    "#iterate over output files\n",
    "for f in flist:\n",
    "    print(\"\\nExtracting contents from: {}\".format(f.split('/')[-1]))\n",
    "    #content list items will have order: \"Model\"\t\"Replicate\"\t\"log-likelihood\"\t\"AIC\"\t\"chi-squared\"\t\"theta\"\t\"optimized_params(xxx)\"\n",
    "    with open(f, 'r') as fh:\n",
    "        lines = [line.strip().split('\\t') for line in fh if not line.startswith(\"Model\")]\n",
    "    #strict filtering: sublists must have 7 elements and not contain any \"nan\" entries\n",
    "    content = [l for l in lines if len(l) == 7 and \"nan\" not in l]\n",
    "    if len(lines) == len(content):\n",
    "        print(\"\\tFound {} total replicates.\".format(len(lines)))\n",
    "    else:\n",
    "        print(\"\\tFound {} row entries.\".format(len(lines)))\n",
    "        print(\"\\tRemoved {} row entries due to presence of 'nan' values or incomplete data.\".format(len(lines)-len(content)))\n",
    "        \n",
    "    #let's sort all the rows by AIC, lowest to highest\n",
    "    content.sort(key=lambda x: float(x[3]))\n",
    "        \n",
    "    #add top five entries to summary list\n",
    "    for i in content[:5]:\n",
    "        summary_list.append(i)\n",
    "        \n",
    "    #add top entry to easy list\n",
    "    simple_list.append(content[0])\n",
    "   \n",
    "#make sure results are actually in lists\n",
    "if simple_list and summary_list:\n",
    "    \n",
    "    #sort the list containing only the top entry for each model by order of AIC\n",
    "    simple_list.sort(key=lambda x: float(x[3]))\n",
    "\n",
    "    #create output file 1\n",
    "    out1 = \"Results_Summary_Extended.txt\"\n",
    "    with open(out1, 'a') as fh:\n",
    "        #write tab-delimited file with extended results\n",
    "        fh.write(\"Model\\tReplicate\\tlog-likelihood\\tAIC\\tchi-squared\\ttheta\\toptimized_params\\n\")\n",
    "        for row in summary_list:\n",
    "            for val in row:\n",
    "                fh.write(\"{}\\t\".format(val))\n",
    "            fh.write(\"\\n\")\n",
    "\n",
    "    #create output file 2\n",
    "    out2 = \"Results_Summary_Short.txt\"\n",
    "    with open(out2, 'a') as fh:\n",
    "        #write tab-delimited file with simplified results\n",
    "        fh.write(\"Model\\tReplicate\\tlog-likelihood\\tAIC\\tchi-squared\\ttheta\\toptimized_params\\n\")\n",
    "        for row in simple_list:\n",
    "            for val in row:\n",
    "                fh.write(\"{}\\t\".format(val))\n",
    "            fh.write(\"\\n\")\n",
    "\n",
    "    print(\"\\n\\nSummary files '{0}' and '{1}' have been written to: \\n\\t{2}\\n\\n\".format(out1, out2, file_dir))\n",
    "\n",
    "else:\n",
    "    print(\"\\n\\nNo results were written!\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"Results_Summary_Extended.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"Results_Summary_Short.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "Plotting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '../'\n",
    "os.chdir(file_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Plotting_Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_params = [3.2485,13.6004,0.0389]\n",
    "\n",
    "#**************\n",
    "#Fit the model using these parameters and return the model SFS.\n",
    "model_fit = Plotting_Functions.Fit_Empirical(fs_fw, pts, prefix, \"no_mig\", no_mig, emp_params, fs_folded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotting_Functions.Plot_1D(fs_fw, model_fit, prefix, \"something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotting_Functions.Plot_2D(fs_fw, model_fit, prefix, \"no_mig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='mode.png') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
